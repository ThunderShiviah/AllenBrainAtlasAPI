{
 "metadata": {
  "name": "",
  "signature": "sha256:bd90cd1192ace2d297a367fc6b8977ceb93b85863aa6645c9f847ff9332558d0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      " # Goal\n",
      " Align the example Allen SVG annotation to the example lab image.\n",
      " \n",
      " ## Discussion\n",
      " In this case, I'm trying to keep the lab image relatively unaltered and find a mapping that takes the annotation image and geometrically transforms it to something that aligns with our lab image. When I say 'align' I'm implicitly hinting at a metric. I don't currently have a metric and for this problem we probably want to be able to interchange metrics. For simplicity, my initial metric will be whether or not the alignment passes (my) visual inspection. Once I have that I can start looking at more rigorous metrics and will at least have some nice test data to optimize to. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## First Attempt\n",
      "### Overview\n",
      "[These slides](http://www.cs.utexas.edu/~grauman/courses/spring2008/slides/ShapeMatching.pdf) give a nice overview of possible techniques to match our images. What I want to do initially is find a [transformation matrix](https://en.wikipedia.org/wiki/Transformation_matrix) that will give me a simple tranformation between the allen atlas annotation and the lab image. [This website](http://franklinta.com/2014/09/08/computing-css-matrix3d-transforms/) gives a nice overview on computing css matrix 3d tranforms (a.k.a [direct linear tranformations](https://en.wikipedia.org/wiki/Direct_linear_transformation)). \n",
      "\n",
      "### Approach\n",
      "\n",
      "First I'll \n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}